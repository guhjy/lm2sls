---
title: "Diagnostics for 2SLS Regression"
author: "John Fox"
date: "2019-07-26"
bibliography: Diagnostics-for-2SLS-Regression.bib
biblio-style: "apalike"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Diagnostics-for-2SLS-Regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

The **lm2sls** package extends a variety of standard numeric and graphical regression  diagnostics to linear models fit by two-stage least-squares (2SLS) regression, a commonly employed method of instrumental-variables estimation for potentially overidentified structural equations in which there are endogenous regressors. The `fit2sls()` function in the package computes the 2SLS estimator employing a low-level interface not generally intended for direct use, and returns a list containing quantities that faciliate the computation of various diagnostics. The `lm2sls()` function provides a user-friendly formula-based interface to `fit2sls()`.

`lm2sls()` is broadly similar in its usage to the `tsls()` function in the **sem** package and the `ivreg()` function in the **AER** package. Its raison-d'etre therefore is the provision of regression diagnostics. The subject of this vignette is the rationale for the various diagnostics and the use of functions in the **lm2sls** package to compute them, along with functions in other packages (specifically the base-R **stats** package and the **car** and **effects** packages) that work with the `"2sls"` objects produced by `lm2sls()`.

## Review of 2SLS Estimation

I'll need some basic results for 2SLS regression to develop diagnostics and so I review the method briefly here. 2SLS regression was invented independently in the 1950s by @Basmann1957 and Theil [as cited in @Theil1971], who took slightly different but equivalent approaches, both described below, to derive the 2SLS estimator.

We want to estimate the linear model $y = X \beta + \varepsilon$, where $y$ is an $n \times 1$ vector of observation on a response variable, $X$ is an $n \times p$ matrix of regressors, typically with an initial columns of $1$s for the regression constant, $\beta$ is a $p \times 1$ vector of regression coefficients to be estimated from the data, and $\varepsilon$ is an $n \times 1$ vector of errors assumed to be distributed $N_n(0, \sigma^2 I_n)$ where $N_n$ is the multivariate-normal distribution, $0$ is an $n \times 1$ vector of zeroes, and $I_n$ is the order-$n$ identity matrix. Suppose that some (perhaps all) of the regressors in $X$ are *endogenous*, in the sense that they are thought not to be independent of $\varepsilon$. As a consequence, the *ordinary least-squares* estimator $b_{\mathrm{OLS}} = (X^T X)^{-1} X^T y$ of $\beta$ is generally biased and inconsistent.

Now suppose that we have another set of $q$ *instrumental variables* (IVs) $Z$ that are independent of $\epsilon$, where $q \ge p$. If $q = p$ we can apply the IVs directly to estimate $\beta$, but if $q > p$ we have more IVs than we need. Simply discarding IVs would be inefficient, and 2SLS regression is a procedure for reducing the number of IVs to $p$ by combining them in a sensible way.

The *first stage* of 2SLS regresses all of regressors in the model matrix $X$ on the IVs $Z$ by multivariate ordinary least squares, obtaining the $q \times p$ matrix of regression coefficients $B = (Z^T Z)^{-1} Z^T X$, and the fitted values $\widehat{X} = Z B$. The columns of $B$ are equivalent to the coefficients produced by separate least-squares regressions of each of columns of $X$ on $Z$. If some of the columns of $X$ are exogenous, then these columns also appear in $Z$, and consequently the columns of $\widehat{X}$ pertaining to exogenous regressors simply reproduce the corresponding columns of $X$.

Because the columns of $\widehat{X}$ are linear combinations of the columns of $Z$, they are (asymptotically) uncorrelated with $\varepsilon$, making them suitable IVs for estimating the regression equation. This IV step is the second stage of 2SLS in Theil's approach.

As an alternative, we can obtain exactly the same estimates $b_{\mathrm{2SLS}}$ of $\beta$ by performing an OLS regression of $y$ on $\widehat{X}$, producing $b_{\mathrm{2SLS}} = (\widehat{X}^T \widehat{X}) \widehat{X}^T y$. This is Basmann's approach and it motivates the name "2SLS." 

Whether we think of the second stage as IV estimation or OLS regression, we can combine the two stages into a single formula [see, e.g., @Fox1979]. This is what the `tsls()` function in the **sem** package does, but from the point of view of developing regression diagnostics, it's advantageous to compute the 2SLS estimator by two distinct OLS regressions. This is coincidentally also the approach taken by `ivreg()` in the **AER** package.

## Case-Deletion Diagnostics for 2SLS Regression

As far as I can tell, diagnostics for regression models fit by 2SLS is a relatively neglected topic, but it was addressed briefly by @Belsley-Kuh-Welsch-1980 [pp. 266--268]. Deletion diagnostics directly assess the influence of each case on a fitted regression model by removing the case, refitting the model, and noting how the regression coefficients or other regression outputs, such as the residual standard deviation, change. 

Case-deletion diagnostics can always be obtained by brute-force computation, literally refitting the model with each case removed in turn, but this approach is inefficient and consequently unattractive in large samples. For some classes of statistical models, such as generalized linear models [e.g., @Pregibon1981], computationally less demanding approximations to case-deletion diagnostics are available, and for linear models efficient updating formulas are available (as described, e.g., by Belseley, Kuh, and Welsch) that permit the exact computation of case-deletion diagnostics. As it turns out, and as Belsley, Kuh, and Welsch note, exact updating formulas for 2SLS regression permitting the efficient computation of case-delection statistics were given by @Phillips1977. Phillips's formulas are used in the case-deletion statistics computed in the **lm2sls** package.

Belsley, Kuh, and Welsch specifically address (in my notation) the values of $\mathrm{dfbeta}_i = b_{\mathrm{2SLS}} - b_{\mathrm{2SLS}-i}$ where $b_{\mathrm{2SLS}-i}$ is the estimated vector of regression coefficients with the $i$th case removed. They discuss as well the deleted values of the residual standard deviation $s_{-i}$. (Belsley, Kuh, and Welsch define $s$ as the residual sum of squares divided by $n$; in the **lm2sls** packages, I divide by the residual degrees of freedom, $n - p$ for the full-sample value of $s$ and $n - p - 1$ for the case-deleted values.)

Belsley, Kuh, and Welsch then compute their summary measure of influence on the fitted values (and regression coefficients) $\mathrm{dffits}$ as
$$
\mathrm{dffits}_i = \frac{x_i^T \mathrm{dfbeta_{i}}}{s_{-i} \sqrt{x_i^T (\widehat{X}^T \widehat{X})^{-1} x_i}}
$$
where $x_i^T$ is the $i$th row of the model matrix $X$ and (as before) $\widehat{X}$ is the model matrix of second-stage regressors.

Let $H^*$ represent the $n \times n$ matrix that transforms $y$ into the fitted values, $\widehat{y} = H^* y$. In OLS regression, the analogous quantity is the hat-matrix $H$. Belsley, Kuh, and Welsch note that $H^*$, unlike $H$, is not an orthogonal-projection matrix, projecting $y$ orthogonally onto the subspace spanned by the columns of $X$. (They say that $H^*$ isn't a projection matrix, but that isn't true: It represents an oblique projection of $y$ onto the subspace spanned by the columns of $X$.) In particular, although $H^*$, like $H$, is idempotent ($H^* = H^* H^*$) and $\mathrm{trace}(H^*) = p$, $H^*$, unlike $H$, is asymmetric, and thus its diagonal elements can't be treated as summary measures of leverage, that is, as hatvalues. 

Belsley, Kuh, and Welsch recommend simply using the havalues from the second-stage regression. These are the diagonal entries of $H_2 = \widehat{X}(\widehat{X}^T \widehat{X})^{-1} \widehat{X}^T$. I discuss some alternatives below.

```{r setup}
library(lm2sls)
```


## References
